# -*- coding: utf-8 -*-
"""NPI_study.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I3gHWpYoo8WCMH3wUHTttOG4fGZtN376

# Non-Pharmaceutical Intervention (NPI) cluster randomized study and stepped-wedge analysis randomized study using EoN
- Adaptation of Outbreak_simulations.R code by Lee et al. Code here: https://github.com/leekshaffer/SW-CRT-outbreak
- Primary use is for a speed up in simulation time using Joel C. Miller's Gillespie algorithm implementation in the EoN package. Documentation here: https://epidemicsonnetworks.readthedocs.io/en/latest/index.html
"""

# Load libraries ---------------------------------------------------------------
#!pip install EoN
import EoN
import networkx as nx
from collections import defaultdict
import matplotlib.pyplot as plt
import random
import math
import scipy
from scipy.integrate import odeint
import numpy as np
import matplotlib.patches as mpatches
import os
import calendar
import csv
from os import path
from itertools import product
from datetime import date
from statistics import mean


effects = [[0.5, 70, 0.04, 0.8, 100, 100]]

for effect in effects:
    # Set seed ---------------------------------------------------------------------
    random.seed(0)
    np.random.seed(0)
    
    # Number of simulated trials ---------------------------------------------------
    nsim = 500
    
    # Directory to save results ----------------------------------------------------
    directory_plots = "/Users/Justin/SW-CRT-outbreak/NPI_study/EoN/code_output/"
    
    """# Changeable simulation parameters
    - Population structure parameters, Epidemic parameters, Trial start and end dates, General CRT parameters, Parallel-Arm CRT parameters, SWT parameters
    """
    
    # Population structure parameters ----------------------------------------------
    num_communities = effect[1] # Number of communities
    num_clusters_enrolled_per_day = effect[1] # Num. clusters targeted for enrollment. Must be <= to the number of communities
    ave_community_size = 100 # Average size of one community
    community_size_range = 40 # Range of community sizes (sizes are uniformly distributed on this range)
    rate_within = 0.15 # Probability of an edge between two nodes in the same community
    rate_between = 0 # Probability of an edge between two nodes in different communities
    
    # SEIR epidemic parameters -----------------------------------------------------
    direct_NPIE = effect[3] # Leaky multiplicative efficacy of NPI
    beta = 0.04 # Per-time-step hazard of infection for a susceptible nodes from an infectious neighbour
    NPIE_beta = (1 - direct_NPIE) * beta # Per-time-step hazard of infection for a susceptible NPIE node from an infectious neighbour
    num_introductions = 80 # Expected number of importations to the population over two years
    incperiod_shape = 5.807 # Gamma-distribution parameters of incubation and 
                            # infectious period. Parameters are from 
                            # Lauer et al. 2020: https://www.acpjournals.org/doi/10.7326/M20-0504
    incperiod_rate = 1 / 0.948
    infperiod_shape = 1.13
    infperiod_rate = 0.226
    ave_inc_period = math.ceil(incperiod_shape / incperiod_rate)
    ave_inf_period = math.ceil(infperiod_shape / infperiod_rate)
    FixInc = 0
    
    # Speed up simulation or not by assuming constant external forcing -------------
    speed_up = True
    
    # Calculate R0 -----------------------------------------------------------------
    R0 = (1 - (infperiod_rate / (infperiod_rate+beta)) ** infperiod_shape) * (((ave_community_size - 1) * (1 - rate_within) * rate_within + 
         (num_communities - 1) * ave_community_size * (1 - rate_between) * rate_between + 
         ((ave_community_size-1) * rate_within + (num_communities - 1) * ave_community_size * rate_between) ** 2)/
         ((ave_community_size-1) * rate_within + (num_communities - 1) * ave_community_size * rate_between) - 1)
    
    # Trial start and end date -----------------------------------------------------
    trial_start_day = 21 # First day of trial enrollment, relative to start of epidemic
    trial_length = 14 # Days after start to follow up
    
    # General CRT Parameters -------------------------------------------------------
    cluster_coverage = effect[0] # Target community enrollment proportion
    
    # Parallel-Arm CRT Parameters --------------------------------------------------
    if (num_clusters_enrolled_per_day > num_communities):
       raise NameError("Enrolling too many communities!")
    enrollment_period = 1 # Num. of days over which subjects are enrolled
    
    """
    # SWT Parameters ---------------------------------------------------------------
    step_interval = 28 # Number of days between crossover events
    first_crossover = 84 # First crossover event: should be equal to trial_start_day or a multiple of step_interval after
    num_clusters_per_step = 4 # Number of clusters enrolled per crossover event
    num_steps = num_communities / num_clusters_per_step # Number of crossover events
    if (num_steps * num_clusters_per_step > num_clusters_enrolled_per_day * enrollment_period):
       raise NameError("Crossing over too many communities!")
    if (first_crossover + (num_steps - 1) * step_interval >  trial_start_day + trial_length):
       raise NameError("Final enrollment is after trial ends!")
    """
    
    # CRT or SWT trial design ------------------------------------------------------
    trial_design = "CRT"
    
    """# Methods to set up randomized-control trial
    
    ## Set SEIR epidemic parameters
    """
    
    # Describe transition rates through H and J graphs for SEIR epidemic -----------
    H = nx.DiGraph()
    H.add_node('S_u')
    H.add_node('S_t')
    if speed_up:
        # Rate calculated from mean of extF of single simulation previously run ----
        background_infected = effect[5]
        prob_inf_fromsource_u = 1 - np.exp(-5.936761e-07 * background_infected)
        prob_inf_fromsource_t = 1 - np.exp(-(1 - direct_NPIE) * 5.936761e-07 * background_infected)
        H.add_edge('S_u', 'E', rate = prob_inf_fromsource_u, weight_label='susc_u2expose_weight')
        H.add_edge('S_t', 'E', rate = prob_inf_fromsource_t, weight_label='susc_t2expose_weight')
    else:
        # Spontaneous transitions from S_u to E and S_t to E are handled instead by
        # the below method 'infect_study_from_src' ---------------------------------
        H.add_edge('S_u', 'E', rate = 0, weight_label='susc_u2expose_weight')
        H.add_edge('S_t', 'E', rate = 0, weight_label='susc_t2expose_weight')
    H.add_edge('E', 'I', rate = 1, weight_label='expose2infect_weight')
    H.add_edge('I', 'R', rate = 1, weight_label='infect2recover_weight')
    
    J = nx.DiGraph()
    J.add_edge(('I', 'S_u'), ('I', 'E'), rate = beta, weight_label='transmission_weight_untreated')
    J.add_edge(('I', 'S_t'), ('I', 'E'), rate = NPIE_beta, weight_label='transmission_weight_treated')
    
    return_statuses = ('S_u', 'S_t', 'E', 'I', 'R')
    
    """## Create trial_network
    - Create isolated_network structure
    - Add edges between isolated_network's connected components
    - Create trial_network, which is the isolated_network with edges added between connected components
    """
    
    def create_trial_network():
        # Create isolated communities ----------------------------------------------
        isolated_network = nx.Graph()
        communities = []
        for comm_num in range(num_communities):
            # Randomly select the community size -----------------------------------
            comm_size = np.random.randint(low=ave_community_size - (community_size_range / 2),
                                          high=ave_community_size + (community_size_range / 2) + 1,
                                          size=1)[0]
        
            # Create the community -------------------------------------------------
            comm_network = nx.fast_gnp_random_graph(comm_size, rate_within)
    
            # Check sequential-ness of comm_network --------------------------------
            should_be = 0
            for node in np.sort(list(comm_network.nodes())):
                if node != should_be:
                    print(np.sort(list(comm_network.nodes())))
                    print("Sequential-ness broken!")
                should_be += 1
    
            # Relabeling of nodes required for all communities besides the first ---
            if (len(communities) > 0):
                new_node_names = dict()
                counter = 0
                for old_node_name in list(comm_network.nodes()):
                    new_node_names[old_node_name] = (counter + max(list(isolated_network.nodes())) + 1)
                    counter += 1
                comm_network = nx.relabel_nodes(comm_network, new_node_names)
    
            # Add the community to the isolated_network ----------------------------
            isolated_network.add_nodes_from(comm_network.nodes())
            isolated_network.add_edges_from(comm_network.edges())
    
            # Add the community to the communities list ----------------------------
            communities.append(comm_network)
    
        # Check for duplicates in communities --------------------------------------
        for comm_dex_one in range(len(communities)):
            for comm_dex_two in range((comm_dex_one + 1), len(communities)):
                if len(set(list(communities[comm_dex_one].nodes())).intersection(set(list(communities[comm_dex_two].nodes())))) > 0:
                    print(communities[comm_dex_one].nodes())
                    print(communities[comm_dex_two].nodes())
                    raise NameError("Duplicate in communities: " + str(comm_dex_one) + " and " + str(comm_dex_two))
    
        # Add between community edges if needed ------------------------------------
        trial_network = isolated_network.copy()
        if (rate_between > 0):
            for cc_one in range(len(communities)):
                for cc_two in range(cc_one, len(communities)):
                    for node_cc_one in cc_one.nodes():
                        for node_cc_two in cc_two.nodes():
                            if (np.random.binomial(n=1, p=rate_between, size=1)[0] == 1):
                                trial_network.add_edge_from(node_cc_one, node_cc_two)
    
        # Check for sequential-ness ------------------------------------------------
        should_be = 0
        for node in np.sort(list(trial_network.nodes())):
            if node != should_be:
                print(trial_network.nodes())
                raise NameError("Sequential-ness broken.")
            should_be += 1
    
        return communities, trial_network
    
    """## Set transitions on trial_network
    - Set the spontaneous transition rate parameters and transmission rate parameters for the SEIR simulation
    """
    
    # Method to add transitions ----------------------------------------------------
    def set_transitions(trial_network):
        # Add infectious and incubation periods for each node by randomly drawing
        # from the gamma distribution described by the parameters incperiod_shape, 
        # incperiod_rate, infperiod_shape, and, infperiod_rate ---------------------
        node_attribute_inc_dict = {node: 1 / np.random.gamma(shape=incperiod_shape, scale=1 / incperiod_rate, size=1)[0] for node in trial_network.nodes()}
        node_attribute_inf_dict = {node: 1 / np.random.gamma(shape=infperiod_shape, scale=1 / infperiod_rate, size=1)[0] for node in trial_network.nodes()}
        
        # Add spontaneous introductions for each node ------------------------------
        node_attribute_intro_untreat_dict = {node: 1 for node in trial_network.nodes()}
        node_attribute_intro_treat_dict = {node: 1 for node in trial_network.nodes()}
        
        # Set node attributes ------------------------------------------------------
        nx.set_node_attributes(trial_network, values=node_attribute_intro_untreat_dict, name='susc_u2expose_weight')
        nx.set_node_attributes(trial_network, values=node_attribute_intro_treat_dict, name='susc_t2expose_weight')
        nx.set_node_attributes(trial_network, values=node_attribute_inc_dict, name='expose2infect_weight')
        nx.set_node_attributes(trial_network, values=node_attribute_inf_dict, name='infect2recover_weight')
    
        # Add transmission weight to edges for untreated individuals ---------------
        edge_untreat_attribute_dict = {edge: 1 for edge in trial_network.edges()}
        edge_treat_attribute_dict = {edge: 1 for edge in trial_network.edges()}
    
        # Set edge attributes ------------------------------------------------------
        nx.set_edge_attributes(trial_network, values=edge_untreat_attribute_dict, name='transmission_weight_untreated')
        nx.set_edge_attributes(trial_network, values=edge_treat_attribute_dict, name='transmission_weight_treated')
        
        return node_attribute_inc_dict, node_attribute_inf_dict, node_attribute_intro_untreat_dict, node_attribute_intro_treat_dict, edge_untreat_attribute_dict, edge_treat_attribute_dict
    
    """## Pre-assign nodes to treatment or control for a cluster-randomized trial
    - Enroll participants from each community in trial
    - Assign to treatment or control groups
    - Record details of trial in a global dataframe
    """
    
    # Of each community, randomly enroll cluster_coverage % of nodes ---------------
    def assign_trial(communities):
        # Assign each community to either treatment or control (i.e. 1 or 0) -------
        treated = random.sample(list(range(len(communities))), math.floor(len(communities) / 2))
        trial_assignment = [-1] * len(communities)
        for community_dex in range(len(trial_assignment)):
            if community_dex in treated:
                trial_assignment[community_dex] = 1
            else:
                trial_assignment[community_dex] = 0
    
        # Check that the number of communities is correct --------------------------
        if len(communities) != num_communities: raise NameError("Wrong num. communities!")
        if len(trial_assignment) != num_communities: raise NameError("Wrong num. communities!")
    
        return trial_assignment
    
    """## Schedule when treatment groups will receive treatment
    - Schedule is dependent on trial design (i.e. CRT or SWT)
    """
    
    def schedule_treatment(trial_assignment):
        treatment_schedule = []
        if (trial_design == "CRT"):
            treatment_schedule.append(trial_start_day)
        elif (trial_design == "SWT"):
            raise NameError("SWT not ready yet to be implemented.")
            treatment_schedule = [None] * len(trial_assignment)
            # Individuals assigned to treatment will receive treatment staggered
            # throughout from first day of trial to end of trial -------------------
            already_crossed = []
            for crossover_date in range(first_crossover,
                                        trial_start_day + trial_length, 
                                        step_interval):
                to_cross_over = random.sample((set([i for i, x in enumerate(trial_assignment) if x == 1]) - set(already_crossed)),
                                              num_clusters_per_step)
                treatment_schedule[to_cross_over] = crossover_date
                already_crossed.append(to_cross_over)
        return treatment_schedule
    
    """## Enroll susceptible individuals for cluster-randomized trial
    - Enroll 'cluster_coverage' % of susceptible individuals from each cluster
    """
    
    def enroll_participants(communities, susceptibles):
        enrolled_participants = []
        for comm_dex in range(len(communities)):
            susc_in_comm = list(set(communities[comm_dex].nodes()).intersection(set(susceptibles)))
            if len(susc_in_comm) < 2:
                raise NameError("Not enough susceptibles available in community for proper trial.")
            enrolled = random.sample(susc_in_comm, math.floor(len(susc_in_comm) * cluster_coverage))
            if len(enrolled) != math.floor(len(susc_in_comm) * cluster_coverage):
                raise NameError("Enrolled wrong number of individuals from community.")
            enrolled_participants.append(enrolled)
        
        if len(enrolled_participants) != num_communities: raise NameError("Wrong num. communities!")
    
        return enrolled_participants
    
    """## External forcing of source infections
    - Represents the external forcing of infection from the source population to the study population
    """
    
    def create_source_infection_schedule():
        # Initialize schedule ------------------------------------------------------
        t = list(range(trial_start_day + trial_length + enrollment_period - 1))
    
        # Compartments of source population ----------------------------------------
        N = 50000 # Total population
        S0 = N - 1 # Initialize susceptible
        E10, E20, E30 = 0, 0, 0 # Initialize exposed
        I10, I20, I30 = 1, 0, 0 # Initialize infecteds
        R0 = 0 # Initialize recovered
        y0 = S0, E10, E20, E30, I10, I20, I30, R0 # Set initial conditions vector
       
        # Rates of source population -----------------------------------------------
        betahat = 0.94
        a1 = 0.19
        a2 = 0.6
        atau = 27.79
        sigma = 0.14
        gamma = 0.33
    
        # Source model differential equations
        def deriv(y, t, N, betahat, a1, a2, atau, sigma, gamma):
            # Load current compartments --------------------------------------------
            S, E1, E2, E3, I1, I2, I3, R = y
            
            # Calculate deltas -----------------------------------------------------
            beta = betahat * (1 - a2/(1 + math.exp(-a1 * (t - atau))))
            dS = -beta * S * (I1+I2+I3) / (S+E1+E2+E3+I1+I2+I3+R)
            dE1 = beta * S * (I1+I2+I3) / (S+E1+E2+E3+I1+I2+I3+R) - sigma * 3 * E1
            dE2 = sigma * 3 * E1 - sigma * 3 * E2
            dE3 = sigma * 3 * E2 - sigma * 3 * E3
            dI1 = sigma * 3 * E3 - gamma * 3 * I1
            dI2 = gamma * 3 * I1 - gamma * 3 * I2
            dI3 = gamma * 3 * I2 - gamma * 3 * I3
            dR = gamma * 3 * I3
    
            return dS, dE1, dE2, dE3, dI1, dI2, dI3, dR
    
        # Integrate over time vector, t --------------------------------------------
        out = odeint(deriv, y0, t, args=(N, betahat, a1, a2, atau, sigma, gamma))
        S, E1, E2, E3, I1, I2, I3, R = out.T
      
        return t, S, E1, E2, E3, I1, I2, I3, R
    
    """# Run trial simulations
    
    ## (Non-speed-up) Helper method to infect study population nodes using the source population
    
    def infect_study_from_src(extFs_u, extFs_t, susceptibles, source_num_inf):
        # Create current dictionaries of the current susceptibles from the 
        # dictionaries of extF -----------------------------------------------------
        susc_extFs_u = dict()
        susc_extFs_t = dict()
        susc_u = []
        susc_t = []
        for susceptible_node in susceptibles:
            if susceptible_node in extFs_u.keys():
                susc_extFs_u[susceptible_node] = extFs_u[susceptible_node]
                susc_u.append(susceptible_node)
            else:
                susc_extFs_t[susceptible_node] = extFs_t[susceptible_node]
                susc_t.append(susceptible_node)
        
        # Get probability of infection based on: (1) number of infections in the
        # source population (2) hazard of external forcing based on population 
        # of nodes that are currently susceptible and either treated or not --------
        if len(susc_extFs_u) > 0:
            prob_inf_fromsource_u = 1 - np.exp(-mean(susc_extFs_u.values()) * source_num_inf)
        if len(susc_extFs_t) > 0:
            prob_inf_from_source_t = 1 - np.exp(-(1 - direct_NPIE) * mean(susc_extFs_t.values()) * source_num_inf)
    
        # Infect study population nodes from the source population -----------------
        infected_nodes_from_src = []
        if len(susc_extFs_u) > 0:
            res_infect_u = list(np.random.binomial(n=1, p=prob_inf_fromsource_u, size=len(susc_u)))
            for u_index in range(len(res_infect_u)):
                if res_infect_u[u_index] == 1:
                    infected_nodes_from_src.append(susc_u[u_index])
        if len(susc_extFs_t) > 0:
            res_infect_t = list(np.random.binomial(n=1, p=prob_inf_fromsource_u, size=len(susc_t)))
            for t_index in range(len(res_infect_t)):
                if res_infect_t[t_index] == 1:
                    infected_nodes_from_src.append(susc_t[t_index])
    
        return infected_nodes_from_src
    
    ## (Non-speed-up) Loop to run trial simulations
    
    for sim_num in range(nsim):
        # Create trial_network -----------------------------------------------------
        communities, trial_network = create_trial_network()
    
        # Set transitions of trial_network -----------------------------------------
        node_attribute_inc_dict, node_attribute_inf_dict, node_intro_untreat_dict, node_intro_treat_dict, edge_untreat_attribute_dict, edge_treat_attribute_dict = set_transitions(trial_network)
        
        # Assign clusters to treatment or control ----------------------------------
        trial_assignment = assign_trial(communities)
    
        # Schedule when treatment groups receive treatment -------------------------
        treatment_schedule = schedule_treatment(trial_assignment)
    
        # Solve for when infections occur from the source population ---------------
        times, S_src, E1_src, E2_src, E3_src, I1_src, I2_src, I3_src, R_src = create_source_infection_schedule()
        
        # Solve for global external forcing per community based on size ------------
        comm_sizes = [len(elem) for elem in communities]
        sumsqrt = sum([math.sqrt(elem) for elem in comm_sizes])
        extF = -np.log(1 - num_introductions / (np.sqrt(comm_sizes) * sumsqrt)) / np.trapz(I1_src + I2_src + I3_src, times)
        
        # Create dictionaries with key: node, and value: extF value per community. 
        # First dictionary is for untreated individuals and second dictionary is for
        # treated individuals ------------------------------------------------------
        extFs_u = dict()
        extFs_t = dict()
        for comm_dex in range(len(communities)):
            for node in communities[comm_dex].nodes():
                extFs_u[node] = extF[comm_dex]
        
        # Initialize that everyone is initially susceptible in the study population
        # as well as compartment trajectories --------------------------------------
        curr_IC = {node: 'S_u' for node in trial_network.nodes()}
        t = None
        S_u = None
        S_t = None
        E = None
        I = None
        R = None
    
        # Run epidemic day by day --------------------------------------------------
        day = 0
        while day < (trial_start_day + trial_length):
            # Double check that there are no longer 'S' nodes in the graph ---------
            if 'S' in curr_IC.values():
                raise NameError("'S' exists in the graph")
    
            # Find current susceptibles --------------------------------------------
            susceptibles = []
            for key in curr_IC.keys():
                if curr_IC[key] == 'S_u' or curr_IC[key] == 'S_t':
                      susceptibles.append(key)
    
            # Look at treatment schedule to see if treatment is needed -------------
            if day in treatment_schedule:
                # Enroll 'cluster_coverage' % of susceptible individuals from each
                # cluster ----------------------------------------------------------
                enrolled_participants = enroll_participants(communities, susceptibles)
    
                # Find communities that need treatment applied ---------------------
                comm_treat_dexs = [i for i, x in enumerate(trial_assignment) if x == 1]
    
                # Update extFs_u, extFs_t, and change status from S_u to S_t for 
                # each enrolled individual of each community -----------------------
                to_treat_nodes = []
                for comm_treat_dex in comm_treat_dexs:
                    to_treat_nodes = to_treat_nodes + enrolled_participants[comm_treat_dex]
                    for to_treat_node in enrolled_participants[comm_treat_dex]:
                        # Delete from extFs_u and add to extFs_t -------------------
                        del extFs_u[to_treat_node]
                        extFs_t[to_treat_node] = extF[comm_treat_dex]
                
                        # Add assigned treated nodes that are S_u to S_t -----------
                        if curr_IC[to_treat_node] == 'S_u':
                            curr_IC[to_treat_node] = 'S_t'
                        else:
                            raise NameError('Assigned treatment to someone who is no longer susceptible.')
    
            # Get source number of infections at time point, t ---------------------
            source_num_inf = I1_src[day] + I2_src[day] + I3_src[day]
    
            # Infect study population from source ----------------------------------
            infected_nodes_from_src = infect_study_from_src(extFs_u, extFs_t, susceptibles, source_num_inf)
            if len(infected_nodes_from_src) > 0:
                for infected_node_from_src in infected_nodes_from_src:
                    curr_IC[infected_node_from_src] = 'E'
            
            # Run for one time step ------------------------------------------------
            if 'E' in curr_IC.values() or 'I' in curr_IC.values():
                full_net_one_step = EoN.Gillespie_simple_contagion(trial_network, H, J, curr_IC, return_statuses, tmax = 1, return_full_data=True)    
                t_one_step = full_net_one_step.t()
                S_u_one_step = full_net_one_step.summary()[1]['S_u']
                S_t_one_step = full_net_one_step.summary()[1]['S_t']
                E_one_step = full_net_one_step.summary()[1]['E']
                I_one_step = full_net_one_step.I()
                R_one_step = full_net_one_step.R()
            else:
                t_one_step = np.array([1])
                S_u_one_step = len([i for i, x in enumerate(curr_IC.values()) if x == "S_u"])
                S_t_one_step = len([i for i, x in enumerate(curr_IC.values()) if x == "S_t"])
                E_one_step = len([i for i, x in enumerate(curr_IC.values()) if x == "E"])
                I_one_step = len([i for i, x in enumerate(curr_IC.values()) if x == "I"])
                R_one_step = len([i for i, x in enumerate(curr_IC.values()) if x == "R"])
    
            # Concatenate results of the single time step --------------------------
            if ((t is None) and (S_u is None) and (S_t is None) and (E is None) and (I is None) and (R is None)):
                t = t_one_step
                S_u = S_u_one_step
                S_t = S_t_one_step
                E = E_one_step
                I = I_one_step
                R = R_one_step
            else:
                t = np.concatenate((t, (t_one_step + t[-1])), axis=None)
                S_u = np.concatenate((S_u, S_u_one_step), axis=None)
                S_t = np.concatenate((S_t, S_t_one_step), axis=None)
                E = np.concatenate((E, E_one_step), axis=None)
                I = np.concatenate((I, I_one_step), axis=None)
                R = np.concatenate((R, R_one_step), axis=None)
            
            # Get initial conditions for next step of simulation -------------------
            if 'E' in curr_IC.values() or 'I' in curr_IC.values():
                nodes_one_step_final = full_net_one_step.get_statuses(list(trial_network.nodes()), t_one_step[-1])
                curr_IC = defaultdict(lambda: 'S_u')
                for node in trial_network.nodes():
                    status = nodes_one_step_final[node]
                    curr_IC[node] = status
            
            # Update day of simulation ---------------------------------------------
            day += 1
    
    ## (Speed-up) Loop to run trial simulations
    - Assume constant forcing of infections from external population
    """
    
    if not (path.exists(directory_plots)):
        os.mkdir(directory_plots)
    
    if not (path.exists(directory_plots + "csvs/")):
        os.mkdir(directory_plots + "csvs/")
    
    file_name_params = str(cluster_coverage) + "_" + str(num_communities) + "_" + str(beta) + "_" + str(direct_NPIE) + "_" + str(ave_community_size) + "_" + str(background_infected)
    batch_folder_name = directory_plots + "csvs/" + file_name_params + "/"
    if not (path.exists(batch_folder_name)):
        os.mkdir(batch_folder_name)
    
    cumul_to_save_csv = []
    cumul_t = []
    cumul_I = []
    cumul_control = []
    cumul_treatment = []
    for sim_num in range(nsim):
        print('Iteration: ' + str(sim_num))
        # Create trial_network -----------------------------------------------------
        communities, trial_network = create_trial_network()
    
        # Set transitions of trial_network -----------------------------------------
        node_attribute_inc_dict, node_attribute_inf_dict, node_intro_untreat_dict, node_intro_treat_dict, edge_untreat_attribute_dict, edge_treat_attribute_dict = set_transitions(trial_network)
        
        # Assign clusters to treatment or control ----------------------------------
        trial_assignment = assign_trial(communities)
        
        # Check if there are correct number of assignments -------------------------
        num_to_be_treated = trial_assignment.count(1)
        if (num_to_be_treated != math.floor(len(communities) / 2)):
            raise NameError("Number of clusters assigned to treatment not correct.")
    
        # Schedule when treatment groups receive treatment -------------------------
        treatment_schedule = schedule_treatment(trial_assignment)
        
        # Initialize that everyone is initially susceptible in the study population
        # as well as compartment trajectories --------------------------------------
        curr_IC = {node: 'S_u' for node in trial_network.nodes()}
        t = None
        S_u = None
        S_t = None
        E = None
        I = None
        R = None
    
        # Split epidemic in to two: up to treatment day and after treatment day ----
        full_first_half = EoN.Gillespie_simple_contagion(trial_network, H, J, curr_IC, return_statuses, tmax = trial_start_day, return_full_data=True)    
        t_first_half = full_first_half.t()
        S_u_first_half = full_first_half.summary()[1]['S_u']
        S_t_first_half = full_first_half.summary()[1]['S_t']
        E_first_half = full_first_half.summary()[1]['E']
        I_first_half = full_first_half.I()
        R_first_half = full_first_half.R()
        
        # Get currently susceptible individuals ------------------------------------
        nodes_first_half_final = full_first_half.get_statuses(list(trial_network.nodes()), t_first_half[-1])
        curr_IC = defaultdict(lambda: 'S_u')
        for node in trial_network.nodes():
             status = nodes_first_half_final[node]
             curr_IC[node] = status
        susceptibles = []
        for key in curr_IC.keys():
            if curr_IC[key] == 'S_u' or curr_IC[key] == 'S_t':
                susceptibles.append(key)
    
        # Enroll 'cluster_coverage' % of susceptible individuals from each cluster -
        enrolled_participants = enroll_participants(communities, susceptibles)
    
        # Find communities that need treatment applied -----------------------------
        comm_treat_dexs = [i for i, x in enumerate(trial_assignment) if x == 1]
    
        # Change status from S_u to S_t for each enrolled individual of each 
        # community ----------------------------------------------------------------
        to_treat_nodes = []
        for comm_treat_dex in comm_treat_dexs:
            to_treat_nodes = to_treat_nodes + enrolled_participants[comm_treat_dex]
            for to_treat_node in enrolled_participants[comm_treat_dex]:
                # Add assigned treated nodes that are S_u to S_t -------------------
                if curr_IC[to_treat_node] == 'S_u':
                    curr_IC[to_treat_node] = 'S_t'
                else:
                    raise NameError('Assigned treatment to someone who is no longer susceptible.')
        
        # Run second half of simulation. Only difference with first call is the
        # modified curr_IC argument ------------------------------------------------
        full_second_half = EoN.Gillespie_simple_contagion(trial_network, H, J, curr_IC, return_statuses, tmax = trial_length, return_full_data=True)    
        t_second_half = full_second_half.t()
        S_u_second_half = full_second_half.summary()[1]['S_u']
        S_t_second_half = full_second_half.summary()[1]['S_t']
        E_second_half = full_second_half.summary()[1]['E']
        I_second_half = full_second_half.I()
        R_second_half = full_second_half.R()
    
        # Concatenate first half with second half ----------------------------------
        t = np.concatenate((t_first_half, (t_second_half + t_first_half[-1])), axis=None)
        S_u = np.concatenate((S_u_first_half, S_u_second_half), axis=None)
        S_t = np.concatenate((S_t_first_half, S_t_second_half), axis=None)
        E = np.concatenate((E_first_half, E_second_half), axis=None)
        I = np.concatenate((I_first_half, I_second_half), axis=None)
        R = np.concatenate((R_first_half, R_second_half), axis=None)
    
        # Create .csv to save of simulation ----------------------------------------
        to_save_csv = [str(t_second_half[-1])]
        status_dict = full_second_half.get_statuses(list(trial_network.nodes()), t_second_half[-1])
        for comm_dex in range(len(communities)):
            for node in np.sort(list(communities[comm_dex].nodes())):
                if node in enrolled_participants[comm_dex]:
                    enrolled = 1
                else:
                    enrolled = 0
                treated = trial_assignment[comm_dex]
                status = status_dict[node]
                degree = trial_network.degree[node]
                unicode_to_add = str(node) + "_" + str(comm_dex) + "_" + str(treated) + "_" + str(enrolled) + "_" + str(status) + "_" + str(degree)
                to_save_csv.append(unicode_to_add)
        cumul_to_save_csv.append(to_save_csv)
    
        # Save the control and treatment time series of infections -----------------
        control_t_series = []
        treatment_t_series = []
        for curr_t in t_first_half:
            curr_t_control = 0
            curr_t_treatment = 0
            status_dict = full_first_half.get_statuses(list(trial_network.nodes()), curr_t)
            for comm_dex in range(len(communities)):
                for node in communities[comm_dex].nodes():
                    if status_dict[node] == "I":
                        if trial_assignment[comm_dex] == 1:
                            curr_t_treatment += 1
                        else:
                            curr_t_control += 1
            control_t_series.append(curr_t_control)
            treatment_t_series.append(curr_t_treatment)
        for curr_t in t_second_half:
            curr_t_control = 0
            curr_t_treatment = 0
            status_dict = full_second_half.get_statuses(list(trial_network.nodes()), curr_t)
            for comm_dex in range(len(communities)):
                for node in communities[comm_dex].nodes():
                    if status_dict[node] == "I":
                        if trial_assignment[comm_dex] == 1:
                            curr_t_treatment += 1
                        else:
                            curr_t_control += 1
            control_t_series.append(curr_t_control)
            treatment_t_series.append(curr_t_treatment)
        cumul_t.append(t)
        cumul_I.append(I)
        cumul_control.append(control_t_series)
        cumul_treatment.append(treatment_t_series)
    
        # Check that the number of nodes in network is within our expectation ------
        if (trial_network.number_of_nodes() < ((ave_community_size - (community_size_range / 2)) * num_communities) or
            trial_network.number_of_nodes() > ((ave_community_size + (community_size_range / 2) + 1) * num_communities)):
            raise NameError("Number of nodes in network is not within expectation.")
    
        # Check that the number enrolled is within our expectation -----------------
        tot_enrolled_participants = 0
        for enrolled_participant_cc in enrolled_participants:
            tot_enrolled_participants += len(enrolled_participant_cc)
        if (tot_enrolled_participants < (cluster_coverage * ((ave_community_size - (community_size_range / 2)) * num_communities))):
            raise NameError("Number of enrolled participants is too low.")
        if (tot_enrolled_participants > (cluster_coverage * ((ave_community_size + (community_size_range / 2) + 1) * num_communities))):
            raise NameError("Number of enrolled participants is too high.")
    
        # Check that if rate_between == 0, there are no edges between ccs ----------
        if (rate_between == 0):
            tot_edges_communities = 0
            for community in communities:
                tot_edges_communities += community.number_of_edges()
            if tot_edges_communities != trial_network.number_of_edges():
                raise NameError("Number of edges between communities and trial network are not same.")
    
    with open(batch_folder_name + "batch_res.csv", 'w') as out_f:
        for l in range(len(cumul_to_save_csv)):
            for l_two in range(len(cumul_to_save_csv[l])):
                out_f.write(cumul_to_save_csv[l][l_two] + ",")
            out_f.write("\n")
